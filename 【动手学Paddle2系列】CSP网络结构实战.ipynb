{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 【动手学Paddle2.0系列】CSP网络结构实战\n",
    "\n",
    "\n",
    "## 0 理论介绍\n",
    "\n",
    "&emsp;&emsp;Cross Stage Partial Network(CSPNet)就是从网络结构设计的角度来解决以往工作在推理过程中需要很大计算量的问题。作者认为推理计算过高的问题是由于网络优化中的梯度信息重复导致的。CSPNet通过将梯度的变化从头到尾地集成到特征图中，在减少了计算量的同时可以保证准确率。CSPNet是一种处理的思想，可以和ResNet、ResNeXt和DenseNet结合。\n",
    "\n",
    "\n",
    "其核心思想就是将输入切分。其目的在于提出一种新的特征融合方式（降低计算量的同时保证精度）。\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/59e99a47dbc045f7a07f7243832a3d9670df47b5f5e34bf387b937ba64854c1a\" width = \"800\"></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "\n",
    "* **[CSPNet](https://arxiv.org/pdf/1911.11929.pdf)提出主要解决了以下三个问题：**\n",
    "\n",
    "1. 增强CNN的学习能力，能够在轻量化的同时保持准确性。\n",
    "1. 降低计算瓶颈。\n",
    "1. 降低内存成本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 网络结构对比\n",
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b39640ece0ca42398ea520eefe05da0ba26c95eb5b364762979a958dba7e78a5\" width = \"800\"></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 实验\n",
    "\n",
    "\n",
    "\n",
    "&emsp;&emsp;本次教程通过图像分类任务对CSP的有效性进行验证。使用的数据集为Paddle2.0中的[Flowers 数据集](https://www.robots.ox.ac.uk/~vgg/data/flowers/)。使用darknet53作为baseline。使用CSP结构作为提升点，完成实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### **核心代码讲解**\n",
    "\n",
    "\n",
    "* **知识点**\n",
    "\n",
    "\n",
    "&emsp;&emsp;在CSPDarknet中，其主要结构未被更改，只是在每个层级中添加了CSP结构，在该教程中，复现代码主要参考了飞桨官方复现代码，以及咩酱大佬的复现代码。CSP结构如理论介绍中的结构图所示，其需要三层卷积，左侧卷积、右侧卷积以及一层Neck。其核心代码如下所示，在Darknet的每个层级中都需要应用相同三层卷积。\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "class BasicBlock(nn.Layer):\n",
    "    def __init__(self, input_channels, output_channels, name=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self._conv1 = ConvBNLayer(\n",
    "            input_channels, output_channels, 1, 1, 0, name=name + \".0\")\n",
    "        self._conv2 = ConvBNLayer(\n",
    "            output_channels, output_channels * 2, 3, 1, 1, name=name + \".1\")\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self._conv1(inputs)\n",
    "        x = self._conv2(x)\n",
    "        return paddle.add(x=inputs, y=x)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# stage 0\n",
    "self.stage1_conv1 = ConvBNLayer(\n",
    "            32, 64, 3, 2, 1, name=\"stage.0.csp0\")\n",
    "self.stage1_conv2 = ConvBNLayer(\n",
    "            64, 64, 1, 1, 1, name=\"stage.0.csp1\")\n",
    "\n",
    "self._basic_block_01 = BasicBlock(64, 32, name=\"stage.0.0\")\n",
    "self.stage1_conv4 = ConvBNLayer(\n",
    "            64, 64, 1, 1, 0, name=\"stage.0.csp3\")\n",
    "self._downsample_0 = ConvBNLayer(\n",
    "            128, 64, 1, 1, 1, name=\"stage.0.downsample\")\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型可视化\n",
    "\n",
    "通过模型可视化，大家可以发现，在网络结构中加入了CSP结构之后，网络模型的参数量从41645640下降到了19047240，模型的参数量大大下降。但是由于我们在网络结构中每个stage中都增加了四层卷积，因此，模型的大小也增加了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from work.darknet53 import CSP_DarkNet53\r\n",
    "\r\n",
    "cnn2 = CSP_DarkNet53(class_dim=10)\r\n",
    "\r\n",
    "model2 = paddle.Model(cnn2)\r\n",
    "\r\n",
    "# 模型可视化\r\n",
    "# model2.summary((64, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/ff715dc82c81415fa80634552e8095f2d03fb1cb4a7844d589da14237b86ce47)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据读取与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz not found, downloading https://dataset.bj.bcebos.com/cifar/cifar-10-python.tar.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "from paddle.vision.datasets import Cifar10\r\n",
    "import paddle.vision.transforms as T\r\n",
    "\r\n",
    "# 该数据集标签值从1开始，但是正常从0开始，故对标签值进行进一步处理\r\n",
    "class FlowerDataset(Cifar10):\r\n",
    "    def __init__(self, mode, transform):\r\n",
    "        super(FlowerDataset, self).__init__(mode=mode, transform=transform)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        image, label = super(FlowerDataset, self).__getitem__(index)\r\n",
    "\r\n",
    "        return image, label \r\n",
    "\r\n",
    "transform = T.Compose([\r\n",
    "                    T.Resize([224,224]),\r\n",
    "                    T.Transpose(),\r\n",
    "                    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\r\n",
    "                ])\r\n",
    "                \r\n",
    "flowers_train =FlowerDataset(mode='train', transform=transform)\r\n",
    "\r\n",
    "flowers_valid = FlowerDataset(mode='test', transform=transform)\r\n",
    "\r\n",
    "\r\n",
    "# 图像预处理\r\n",
    "# transform = T.Compose([\r\n",
    "#     T.Resize([224, 224]),\r\n",
    "#     T.ToTensor(),\r\n",
    "#   ])\r\n",
    "\r\n",
    "# 构建训练集数据加载器\r\n",
    "train_loader = paddle.io.DataLoader(flowers_train, batch_size=64, shuffle=True)\r\n",
    "\r\n",
    "# 构建测试集数据加载器\r\n",
    "valid_loader = paddle.io.DataLoader(flowers_valid, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "\r\n",
    "model2.prepare(optimizer=paddle.optimizer.Adam(parameters=model2.parameters()),\r\n",
    "              loss=nn.CrossEntropyLoss(),\r\n",
    "              metrics=paddle.metric.Accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 782/782 [==============================] - loss: 1.0268 - acc: 0.4020 - 355ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 1.5527 - acc: 0.4445 - 187ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 2/5\n",
      "step 782/782 [==============================] - loss: 1.2340 - acc: 0.6099 - 354ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step  40/157 [======>.......................] - loss: 0.6905 - acc: 0.6207 - ETA: 22s - 190ms/st"
     ]
    }
   ],
   "source": [
    "\r\n",
    "model2.fit(train_loader,\r\n",
    "        valid_loader,\r\n",
    "        epochs=5,\r\n",
    "        verbose=1,\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 对比实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from work.cspdarknet53 import DarkNet53\r\n",
    "\r\n",
    "cnn3 = DarkNet53(class_dim=10)\r\n",
    "\r\n",
    "model3 = paddle.Model(cnn3)\r\n",
    "\r\n",
    "\r\n",
    "# 模型可视化\r\n",
    "# model3.summary((64, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/b088bb1f12664924a351ea609488729adb7e95f6d7324d1db3c6f4dab7297fb5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 782/782 [==============================] - loss: 1.4409 - acc: 0.3489 - 233ms/step         \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 1.5534 - acc: 0.4902 - 169ms/step         \n",
      "Eval samples: 10000\n",
      "Epoch 2/5\n",
      "step 782/782 [==============================] - loss: 0.9414 - acc: 0.5933 - 227ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 1.1782 - acc: 0.6465 - 165ms/step         \n",
      "Eval samples: 10000\n",
      "Epoch 3/5\n",
      "step 782/782 [==============================] - loss: 1.2450 - acc: 0.7077 - 228ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 0.9096 - acc: 0.6902 - 181ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 4/5\n",
      "step 782/782 [==============================] - loss: 0.5926 - acc: 0.7720 - 228ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 0.6070 - acc: 0.7727 - 165ms/step         \n",
      "Eval samples: 10000\n",
      "Epoch 5/5\n",
      "step 782/782 [==============================] - loss: 0.1841 - acc: 0.8134 - 226ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 0.3209 - acc: 0.8045 - 167ms/step         \n",
      "Eval samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn as nn\r\n",
    "\r\n",
    "model3.prepare(optimizer=paddle.optimizer.Adam(parameters=model3.parameters()),\r\n",
    "              loss=nn.CrossEntropyLoss(),\r\n",
    "              metrics=paddle.metric.Accuracy())\r\n",
    "\r\n",
    "\r\n",
    "model3.fit(train_loader,\r\n",
    "        valid_loader,\r\n",
    "        epochs=5,\r\n",
    "        verbose=1,\r\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "\n",
    "\n",
    "&emsp;&emsp;本次教程针对CSP结构进行了介绍，并通过cifar10数据集进行了对比实验。和之前的一样，由于本人比较懒，故只对模型做了5次迭代，大家感兴趣的可以针对不同的数据集进行实验，也可将此思想应用于其他网络结构中，如ResNet等。BTW，通过CSPNet的论文以及YOLOv4的论文我们可以知道CSP结构是能够Work的。\n",
    "\n",
    "\n",
    " [另外，欢迎大家关注我哦。我在AI Studio上获得至尊等级，点亮8个徽章，来互关呀~]( https://aistudio.baidu.com/aistudio/personalcenter/thirdview/228777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
