{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CoordConv实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 理论介绍\n",
    "\n",
    "* CoordConv\n",
    "\n",
    "&emsp;&emsp;即它无法将空间表示转换成笛卡尔空间中的坐标和one-hot像素空间中的坐标。\n",
    "卷积是等变的，也就是说当每个过滤器应用到输入上时，它不知道每个过滤器在哪。我们可以帮助卷积，让它知道过滤器的位置。这一过程需要在输入上添加两个通道实现，一个在i坐标，另一个在j坐标。我们将这个图层成为CoordConv，如下图所示：\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/6a7bcc4d5fc34d35964d0df50310011aa6fd2ec588494ce99cb05b8c50dbcd6c\" width = \"800\"></center>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "&emsp;&emsp;深度学习里的卷积运算是具有平移等变性的,这样可以在图像的不同位置共享统一的卷积核参数,但是这样卷积学习过程中是不能感知当前特征在图像中的坐标的。CoordConv就是通过在卷积的输入特征图中新增对应的通道来表征特征图像素点的坐标,让卷积学习过程中能够一定程度感知坐标来提升检测精度。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 代码实战\n",
    "\n",
    "\n",
    "&emsp;&emsp;本部分根据CoordConv论文并参考飞桨的官方实现完成CoordConv的复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.nn.functional as F\r\n",
    "from paddle import ParamAttr\r\n",
    "from paddle.regularizer import L2Decay\r\n",
    "from paddle.nn import AvgPool2D, Conv2D\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class CoordConv(nn.Layer):\r\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\r\n",
    "        super(CoordConv, self).__init__()\r\n",
    "        self.conv = Conv2D(\r\n",
    "            in_channels + 2, out_channels , kernel_size , stride , padding)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        b = x.shape[0]\r\n",
    "        h = x.shape[2]\r\n",
    "        w = x.shape[3]\r\n",
    "\r\n",
    "        gx = paddle.arange(w, dtype='float32') / (w - 1.) * 2.0 - 1.\r\n",
    "        gx = gx.reshape([1, 1, 1, w]).expand([b, 1, h, w])\r\n",
    "        gx.stop_gradient = True\r\n",
    "\r\n",
    "        gy = paddle.arange(h, dtype='float32') / (h - 1.) * 2.0 - 1.\r\n",
    "        gy = gy.reshape([1, 1, h, 1]).expand([b, 1, h, w])\r\n",
    "        gy.stop_gradient = True\r\n",
    "\r\n",
    "        y = paddle.concat([x, gx, gy], axis=1)\r\n",
    "        y = self.conv(y)\r\n",
    "        return y\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class dcn2(paddle.nn.Layer):\r\n",
    "    def __init__(self, num_classes=1):\r\n",
    "        super(dcn2, self).__init__()\r\n",
    "\r\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding = 1)\r\n",
    "        # self.pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\r\n",
    "\r\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=32, out_channels=64, kernel_size=(3,3),  stride=2, padding = 0)\r\n",
    "        # self.pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\r\n",
    "\r\n",
    "        self.conv3 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=(3,3), stride=2, padding = 0)\r\n",
    "\r\n",
    "        self.offsets = paddle.nn.Conv2D(64, 18, kernel_size=3, stride=2, padding=1)\r\n",
    "        self.mask = paddle.nn.Conv2D(64, 9, kernel_size=3, stride=2, padding=1)\r\n",
    "        self.conv4 = CoordConv(64, 64, (3,3), 2, 1)\r\n",
    "\r\n",
    "        # self.conv4 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=(3,3), stride=2, padding = 1)\r\n",
    "\r\n",
    "        self.flatten = paddle.nn.Flatten()\r\n",
    "\r\n",
    "        self.linear1 = paddle.nn.Linear(in_features=1024, out_features=64)\r\n",
    "        self.linear2 = paddle.nn.Linear(in_features=64, out_features=num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # x = self.pool1(x)\r\n",
    "        # print(x.shape)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # x = self.pool2(x)\r\n",
    "        # print(x.shape)\r\n",
    "\r\n",
    "        x = self.conv3(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # print(x.shape)\r\n",
    "        \r\n",
    "        # offsets = self.offsets(x)\r\n",
    "        # masks = self.mask(x)\r\n",
    "        # print(offsets.shape)\r\n",
    "        # print(masks.shape)\r\n",
    "        x = self.conv4(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # print(x.shape)\r\n",
    "\r\n",
    "        x = self.flatten(x)\r\n",
    "        x = self.linear1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.linear2(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-26     [[64, 3, 32, 32]]     [64, 32, 32, 32]         896      \n",
      "   Conv2D-27     [[64, 32, 32, 32]]    [64, 64, 15, 15]       18,496     \n",
      "   Conv2D-28     [[64, 64, 15, 15]]     [64, 64, 7, 7]        36,928     \n",
      "   Conv2D-31      [[64, 66, 7, 7]]      [64, 64, 4, 4]        38,080     \n",
      "  CoordConv-4     [[64, 64, 7, 7]]      [64, 64, 4, 4]           0       \n",
      "   Flatten-1      [[64, 64, 4, 4]]        [64, 1024]             0       \n",
      "   Linear-1         [[64, 1024]]           [64, 64]           65,600     \n",
      "   Linear-2          [[64, 64]]            [64, 1]              65       \n",
      "===========================================================================\n",
      "Total params: 160,065\n",
      "Trainable params: 160,065\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 26.09\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 27.45\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 160065, 'trainable_params': 160065}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3 = dcn2()\r\n",
    "\r\n",
    "model3 = paddle.Model(cnn3)\r\n",
    "\r\n",
    "model3.summary((64, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet(paddle.nn.Layer):\r\n",
    "    def __init__(self, num_classes=1):\r\n",
    "        super(MyNet, self).__init__()\r\n",
    "\r\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=1, padding = 1)\r\n",
    "        # self.pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\r\n",
    "\r\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=32, out_channels=64, kernel_size=(3,3),  stride=2, padding = 0)\r\n",
    "        # self.pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\r\n",
    "\r\n",
    "        self.conv3 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=(3,3), stride=2, padding = 0)\r\n",
    "\r\n",
    "        self.conv4 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=(3,3), stride=2, padding = 1)\r\n",
    "\r\n",
    "        self.flatten = paddle.nn.Flatten()\r\n",
    "\r\n",
    "        self.linear1 = paddle.nn.Linear(in_features=1024, out_features=64)\r\n",
    "        self.linear2 = paddle.nn.Linear(in_features=64, out_features=num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # x = self.pool1(x)\r\n",
    "        # print(x.shape)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # x = self.pool2(x)\r\n",
    "        # print(x.shape)\r\n",
    "\r\n",
    "        x = self.conv3(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # print(x.shape)\r\n",
    "        \r\n",
    "        \r\n",
    "        x = self.conv4(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        # print(x.shape)\r\n",
    "\r\n",
    "        x = self.flatten(x)\r\n",
    "        x = self.linear1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.linear2(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-1      [[64, 3, 32, 32]]     [64, 32, 32, 32]         896      \n",
      "   Conv2D-2      [[64, 32, 32, 32]]    [64, 64, 15, 15]       18,496     \n",
      "   Conv2D-3      [[64, 64, 15, 15]]     [64, 64, 7, 7]        36,928     \n",
      "   Conv2D-4       [[64, 64, 7, 7]]      [64, 64, 4, 4]        36,928     \n",
      "   Flatten-1      [[64, 64, 4, 4]]        [64, 1024]             0       \n",
      "   Linear-1         [[64, 1024]]           [64, 64]           65,600     \n",
      "   Linear-2          [[64, 64]]            [64, 1]              65       \n",
      "===========================================================================\n",
      "Total params: 158,913\n",
      "Trainable params: 158,913\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 25.59\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 26.95\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 158913, 'trainable_params': 158913}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "# 可视化模型\r\n",
    "\r\n",
    "cnn1 = MyNet()\r\n",
    "\r\n",
    "model1 = paddle.Model(cnn1)\r\n",
    "\r\n",
    "model1.summary((64, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "\n",
    "\n",
    "&emsp;&emsp;相信通过之前的教程，相信大家已经能够熟练掌握了迅速开启训练的方法。所以，之后的教程我都会关注于具体的代码实现以及相关的理论介绍。如无必要，不再进行对比实验。本次教程主要对CoordConv的理论进行了介绍，对其进行了复现，并展示了其在网络结构中的用法。大家可以根据的实际需要，将其移植到自己的网络中。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
